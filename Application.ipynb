{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f826753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Activation, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28185a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_whiteboard(display):\n",
    "    wb_x1, wb_x2, wb_y1, wb_y2 = whiteboard_region[\"x\"][0], whiteboard_region[\"x\"][1], whiteboard_region[\"y\"][0], whiteboard_region[\"y\"][1] \n",
    "    \n",
    "    display[wb_y1-10:wb_y2+12, wb_x1-10:wb_x2+12] = (255, 255, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbe0da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_display():\n",
    "    title = np.zeros((80, 950, 3), dtype=np.uint8)\n",
    "    board = np.zeros((600, 650, 3), dtype=np.uint8)\n",
    "    panel = np.zeros((600, 300, 3), dtype=np.uint8)\n",
    "    board[5:590, 8:645] = (255, 255, 255)\n",
    "    \n",
    "    board = cv2.rectangle(board, (8, 5), (645, 590), (255, 0, 0), 3)\n",
    "    panel = cv2.rectangle(panel, (1, 4), (290, 590), (0, 255, 192), 2)\n",
    "    panel = cv2.rectangle(panel, (22, 340), (268, 560), (255, 255, 255), 1)\n",
    "    panel = cv2.rectangle(panel, (22, 65), (268, 280), (255, 255, 255), 1)\n",
    "    \n",
    "    cv2.line(panel, (145, 340), (145, 560), (255, 255, 255), 1)\n",
    "    cv2.line(panel, (22, 380), (268, 380), (255, 255, 255), 1)\n",
    "    \n",
    "    cv2.putText(title, \"       \" +  window_name,(10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)\n",
    "    cv2.putText(panel, \"Action: \", (23, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "    cv2.putText(panel, \"Best Predictions\", (52, 320), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 1)\n",
    "    cv2.putText(panel, \"Prediction\", (42, 362), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    cv2.putText(panel, \"Accuracy\", (168, 362), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    cv2.putText(panel, actions[0], (95, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.6, action_colors[actions[0]], 1)\n",
    "\n",
    "    display = np.concatenate((board, panel), axis=1)\n",
    "    display = np.concatenate((title, display), axis=0)\n",
    "    \n",
    "    return display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73bb0a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_panel(display):\n",
    "    action_region_pt1, action_region_pt2 = status_regions[\"action\"]\n",
    "    preview_region_pt1, preview_region_pt2 = status_regions[\"preview\"]\n",
    "    label_region_pt1, label_region_pt2 = status_regions[\"labels\"]\n",
    "    acc_region_pt1, acc_region_pt2 = status_regions[\"accs\"]\n",
    "    \n",
    "    display[action_region_pt1[1]:action_region_pt2[1], action_region_pt1[0]:action_region_pt2[0]] = (0, 0, 0)\n",
    "    display[preview_region_pt1[1]:preview_region_pt2[1], preview_region_pt1[0]:preview_region_pt2[0]] = (0, 0, 0)\n",
    "    display[label_region_pt1[1]:label_region_pt2[1], label_region_pt1[0]:label_region_pt2[0]] = (0, 0, 0)\n",
    "    display[acc_region_pt1[1]:acc_region_pt2[1], acc_region_pt1[0]:acc_region_pt2[0]] = (0, 0, 0)\n",
    "    \n",
    "    if crop_preview is not None:\n",
    "        display[preview_region_pt1[1]:preview_region_pt2[1], preview_region_pt1[0]:preview_region_pt2[0]] = cv2.resize(crop_preview, (crop_preview_h, crop_preview_w)) \n",
    "    \n",
    "    if best_predictions:\n",
    "        labels = list(best_predictions.keys())\n",
    "        accs = list(best_predictions.values())\n",
    "        prediction_status_cordinate = [\n",
    "            ((725, 505), (830, 505), (0, 0, 255)),\n",
    "            ((725, 562), (830, 562), (0, 255, 0)),\n",
    "            ((725, 619), (830, 619), (255, 0, 0))\n",
    "        ]\n",
    "        for i in range(len(labels)):\n",
    "            label_cordinate, acc_cordinate, color = prediction_status_cordinate[i]\n",
    "            \n",
    "            cv2.putText(display, labels[i], label_cordinate, cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "            cv2.putText(display, str(accs[i]), acc_cordinate, cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "        \n",
    "        for i in range(len(labels), 3):\n",
    "            label_cordinate, acc_cordinate, color = prediction_status_cordinate[i]\n",
    "            \n",
    "            cv2.putText(display, \"_\", label_cordinate, cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "            cv2.putText(display, \"_\", acc_cordinate, cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "    \n",
    "    cv2.putText(display, current_action, (745, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.6, action_colors[current_action], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57a756b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_crop_rectangle_cordinates(cor1, cor2):\n",
    "    if cor1 is None or cor2 is None:\n",
    "        return\n",
    "    \n",
    "    result = ()\n",
    "    if cor1[1] < cor2[1]:\n",
    "        if cor1[0] > cor2[0]:\n",
    "            result = ( (cor2[0], cor1[1]), (cor1[0], cor2[1]) )\n",
    "        else:\n",
    "            result = (cor1, cor2)\n",
    "    else:\n",
    "        if cor2[0] > cor1[0]:\n",
    "            result = ( (cor1[0], cor2[1]), (cor2[0], cor1[1]) )\n",
    "        else:\n",
    "            result = (cor2, cor1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fe750ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mouse_click_event(event, x, y, flags, params):\n",
    "    if current_action is actions[1]:\n",
    "        whiteboard_draw(event, x, y)\n",
    "    elif current_action is actions[2]:\n",
    "        character_crop(event, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90359663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def whiteboard_draw(event, x, y):\n",
    "    global left_button_down, right_button_down\n",
    "    \n",
    "    wb_x1, wb_x2, wb_y1, wb_y2 = whiteboard_region[\"x\"][0], whiteboard_region[\"x\"][1], whiteboard_region[\"y\"][0], whiteboard_region[\"y\"][1] \n",
    "    \n",
    "    if event is cv2.EVENT_LBUTTONUP:\n",
    "        left_button_down = False\n",
    "    elif event is cv2.EVENT_RBUTTONUP:\n",
    "        right_button_down = False\n",
    "    elif wb_x1 <= x <= wb_x2 and wb_y1 <= y <= wb_y2:\n",
    "        color = (0, 0, 0)\n",
    "        if event in [cv2.EVENT_LBUTTONDOWN, cv2.EVENT_LBUTTONUP, cv2.EVENT_RBUTTONDOWN, cv2.EVENT_RBUTTONUP, cv2.EVENT_MOUSEMOVE]:\n",
    "            if event is cv2.EVENT_LBUTTONDOWN:\n",
    "                color = (0, 0, 0)\n",
    "                left_button_down = True\n",
    "            elif left_button_down and event is cv2.EVENT_MOUSEMOVE:\n",
    "                color = (0, 0, 0)\n",
    "            elif event is cv2.EVENT_RBUTTONDOWN:\n",
    "                color = (255, 255, 255)\n",
    "                right_button_down = True\n",
    "            elif right_button_down and event is cv2.EVENT_MOUSEMOVE:\n",
    "                color = (255, 255, 255)\n",
    "            else:\n",
    "                return\n",
    "\n",
    "            cv2.circle(display, (x, y), 10, color, -1)\n",
    "            cv2.imshow(window_name, display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16b7e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_crop(event, x, y):\n",
    "    global bound_rect_cordinates, lbd_cordinate, lbu_cordinate, crop_preview, display, best_predictions\n",
    "    \n",
    "    wb_x1, wb_x2, wb_y1, wb_y2 = whiteboard_region[\"x\"][0], whiteboard_region[\"x\"][1], whiteboard_region[\"y\"][0], whiteboard_region[\"y\"][1] \n",
    "    \n",
    "    if wb_x1 <= x <= wb_x2 and wb_y1 <= y <= wb_y2:\n",
    "        if event is cv2.EVENT_LBUTTONDOWN:\n",
    "            lbd_cordinate = (x, y)\n",
    "        elif event is cv2.EVENT_LBUTTONUP:\n",
    "            lbu_cordinate = (x, y)\n",
    "\n",
    "        if lbd_cordinate is not None and lbu_cordinate is not None:\n",
    "            bound_rect_cordinates = arrange_crop_rectangle_cordinates(lbd_cordinate, lbu_cordinate)\n",
    "        elif lbd_cordinate is not None:\n",
    "            if event is cv2.EVENT_MOUSEMOVE:\n",
    "                mouse_move_cordinate = (x, y)\n",
    "                mouse_move_rect_cordinates = arrange_crop_rectangle_cordinates(lbd_cordinate, mouse_move_cordinate)\n",
    "                top_cordinate, bottom_cordinate = mouse_move_rect_cordinates[0], mouse_move_rect_cordinates[1]\n",
    "                \n",
    "                display_copy = display.copy()\n",
    "                cropped_region = display_copy[top_cordinate[1]:bottom_cordinate[1], top_cordinate[0]:bottom_cordinate[0]]\n",
    "                filled_rect = np.zeros((cropped_region.shape[:]))\n",
    "                filled_rect[:, :, :] = (0, 255, 0)\n",
    "                filled_rect = filled_rect.astype(np.uint8)\n",
    "                cropped_rect = cv2.addWeighted(cropped_region, 0.3, filled_rect, 0.5, 1.0)\n",
    "                \n",
    "                if cropped_rect is not None:\n",
    "                    display_copy[top_cordinate[1]:bottom_cordinate[1], top_cordinate[0]:bottom_cordinate[0]] = cropped_rect\n",
    "                    cv2.imwrite(\"captured/filled.jpg\", display_copy)\n",
    "                    cv2.imshow(window_name, display_copy)\n",
    "\n",
    "        if bound_rect_cordinates is not None:\n",
    "            top_cordinate, bottom_cordinate = bound_rect_cordinates[0], bound_rect_cordinates[1]\n",
    "            crop_preview = display[top_cordinate[1]:bottom_cordinate[1], top_cordinate[0]:bottom_cordinate[0]].copy()\n",
    "            crop_preview = np.invert(crop_preview)\n",
    "            best_predictions = predict(model, crop_preview)\n",
    "            display_copy = display.copy()\n",
    "            bound_rect_cordinates = lbd_cordinate = lbu_cordinate = None\n",
    "            setup_panel(display)\n",
    "            cv2.imshow(window_name, display)\n",
    "    elif event is cv2.EVENT_LBUTTONUP:\n",
    "        lbd_cordinate = lbu_cordinate = None\n",
    "        cv2.imshow(window_name, display)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "977731a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(32, (5, 5), activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dense(36, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    model.load_weights(path)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "#This code defines and loads a simple convolutional neural network (CNN) model for image classification using Keras.\n",
    "#It creates a Sequential model using Keras. A Sequential model is a linear stack of layers.\n",
    "#It adds the first convolutional layer with 32 filters of size (5, 5) and ReLU (Rectified Linear Unit) activation function. The input_shape parameter specifies the shape of the input data, which is (28, 28, 1) for grayscale images.\n",
    "#It adds Batch Normalization after the first convolutional layer. Batch Normalization helps improve training stability and can lead to faster convergence during training.\n",
    "#It adds a second convolutional layer with 32 filters of size (5, 5) and ReLU activation.\n",
    "#Batch Normalization is applied again after the second convolutional layer.\n",
    "#MaxPooling2D layer with a pool size of (2, 2) is added to downsample the spatial dimensions of the feature maps.\n",
    "#A Dropout layer with a dropout rate of 25% is added to reduce overfitting during training. Dropout randomly sets a fraction of input units to 0 during each update, which helps prevent overfitting.\n",
    "#Another Batch Normalization layer is added.\n",
    "#The Flatten layer is used to flatten the output from the previous layers into a 1D vector. This is necessary before connecting to fully connected (dense) layers.\n",
    "#Two fully connected (Dense) layers are added. The first dense layer has 256 units with ReLU activation, and the second dense layer has 36 units with softmax activation. The softmax activation is often used for multi-class classification, as it outputs a probability distribution over the classes.\n",
    "#The model is compiled with the categorical cross-entropy loss function, Adam optimizer, and accuracy as the evaluation metric. This is a common setup for training classification models.\n",
    "#The model.load_weights(path) statement loads pre-trained weights from a specified file, allowing you to use a pre-trained model for inference.\n",
    "#Finally, the function returns the loaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d0716bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image):\n",
    "    labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (28, 28))\n",
    "    image = image / 255.0\n",
    "    image = np.reshape(image, (1, image.shape[0], image.shape[1], 1))\n",
    "    prediction = model.predict(image)\n",
    "    best_predictions = dict()\n",
    "    \n",
    "    for i in range(3):\n",
    "        max_i = np.argmax(prediction[0])\n",
    "        acc = round(prediction[0][max_i], 1)\n",
    "        if acc > 0:\n",
    "            label = labels[max_i]\n",
    "            best_predictions[label] = acc\n",
    "            prediction[0][max_i] = 0\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    return best_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17fef9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_button_down = False\n",
    "right_button_down = False\n",
    "bound_rect_cordinates = lbd_cordinate = lbu_cordinate = None\n",
    "whiteboard_region = {\"x\": (20, 632), \"y\": (98, 656)}\n",
    "window_name = \"Live Cropped Character Recognition\"\n",
    "best_predictions = dict()\n",
    "crop_preview_h, crop_preview_w = 238, 206\n",
    "crop_preview = None\n",
    "actions = [\"N/A\", \"DRAW\", \"CROP\"]\n",
    "action_colors = {\n",
    "    actions[0]: (0, 0, 255),\n",
    "    actions[1]: (0, 255, 0),\n",
    "    actions[2]: (0, 255, 192)\n",
    "}\n",
    "current_action = actions[0]\n",
    "status_regions = {\n",
    "    \"action\": ((736, 97), (828, 131)),\n",
    "    \"preview\": ((676, 150), (914, 356)),\n",
    "    \"labels\": ((678, 468), (790, 632)),\n",
    "    \"accs\": ((801, 468), (913, 632))\n",
    "}\n",
    "model = load_model(\"../models/best_val_loss_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94a50dab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Arash\\Desktop\\Multimedia Project\\A-to-Z-and-0-to-9-character-recognition-main\\A-to-Z-and-0-to-9-character-recognition-main\\notebooks\\Application.ipynb Cell 12\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Arash/Desktop/Multimedia%20Project/A-to-Z-and-0-to-9-character-recognition-main/A-to-Z-and-0-to-9-character-recognition-main/notebooks/Application.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m pre_action \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Arash/Desktop/Multimedia%20Project/A-to-Z-and-0-to-9-character-recognition-main/A-to-Z-and-0-to-9-character-recognition-main/notebooks/Application.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Arash/Desktop/Multimedia%20Project/A-to-Z-and-0-to-9-character-recognition-main/A-to-Z-and-0-to-9-character-recognition-main/notebooks/Application.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     k \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Arash/Desktop/Multimedia%20Project/A-to-Z-and-0-to-9-character-recognition-main/A-to-Z-and-0-to-9-character-recognition-main/notebooks/Application.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mif\u001b[39;00m k \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39md\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m k \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mc\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Arash/Desktop/Multimedia%20Project/A-to-Z-and-0-to-9-character-recognition-main/A-to-Z-and-0-to-9-character-recognition-main/notebooks/Application.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39mif\u001b[39;00m k \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39md\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "display = setup_display()\n",
    "cv2.imshow(window_name, display)\n",
    "cv2.setMouseCallback(window_name, mouse_click_event)\n",
    "pre_action = None\n",
    "\n",
    "while True:\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord('d') or k == ord('c'):\n",
    "        if k == ord('d'):\n",
    "            current_action = actions[1]\n",
    "        elif k == ord('c'):\n",
    "            current_action = actions[2]\n",
    "        if pre_action is not current_action:\n",
    "            setup_panel(display)\n",
    "            cv2.imshow(window_name, display)\n",
    "            pre_action = current_action\n",
    "    elif k == ord('e'):\n",
    "        clear_whiteboard(display)\n",
    "        cv2.imshow(window_name, display)\n",
    "    elif k == 27:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d608bd2",
   "metadata": {},
   "source": [
    "<u><h4>References</h4></u>\n",
    "<p><a href=\"https://www.kaggle.com/sachinpatel21/az-handwritten-alphabets-in-csv-format\">A-Z Kaggle Dataset</a></p>\n",
    "<p><a href=\"http://yann.lecun.com/exdb/mnist/\">MNIST Dataset</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309bf1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
